{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AsrPm5AhhkUr"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXQ0vg-Eidsi"
   },
   "source": [
    "1. Benchmarks to test contiguousness - list, array, np array. Are Numpy arrays by default contiguous?\n",
    "\n",
    "2. Numpy calls underlying C implementation\n",
    "\n",
    "5. Call BLAS through numpy somehow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "scD1-xnDjcJY"
   },
   "outputs": [],
   "source": [
    "# This creates an array without initializing it\n",
    "a_numpy = np.empty((20000, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95E-jC6e-MVd",
    "outputId": "25faed55-f811-45d2-db63-c721bed3bc70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  ndarray\n",
      "shape:  (20000, 10000)\n",
      "strides:  (80000, 8)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x280000000\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float64\n"
     ]
    }
   ],
   "source": [
    "# As we can see, array is contiguous\n",
    "np.info(a_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNMvPhWh-TIz",
    "outputId": "c5fc5688-968b-493a-eff5-a50b8786709e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of a:  1525.87890625  MB\n",
      "Nr bytes:  1600000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of a: \", a_numpy.nbytes / 1024 / 1024, \" MB\")\n",
    "print(\"Nr bytes: \", a_numpy.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0kGBhny_PfB"
   },
   "source": [
    "Why 160000000 bytes? Because we have float64 elements, and there's 200 million of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0adRLSAN-7wb"
   },
   "source": [
    "<font color=\"red\"> Interesting - Colab doesn't show memory is taken up so far, even though RAM should be mostly full </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYPKhy85P8cL"
   },
   "source": [
    "Let's see how much more memory we're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PA7yRqCR-r_l"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NqVa9TlsA735",
    "outputId": "40b06ec5-76a3-4ed3-9df9-e3e04446c8dc"
   },
   "outputs": [],
   "source": [
    "# Generate random ints between 0-9000 (Uniform dist.)\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html\n",
    "a_numpy = randint.rvs(low=0, high=9000, size=1000000)\n",
    "a_list = list(a_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ejyph6APpnO",
    "outputId": "50ba29dd-b3fa-49c4-f0b9-f59384a249bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python list: Size in MB:  37.71116638183594\n"
     ]
    }
   ],
   "source": [
    "from pympler.asizeof import asizeof\n",
    "\n",
    "print(\"Python list: Size in MB: \", asizeof(a_list) / 1024 / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rERrHhIUQbcW",
    "outputId": "8d190fdb-d058-410b-8f78-fc4f59e1926b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array: Size in MB:  7.6295166015625\n"
     ]
    }
   ],
   "source": [
    "print(\"Numpy array: Size in MB: \", asizeof(a_numpy) / 1024 / 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlkpKigbQsrb"
   },
   "source": [
    "<font color=\"orange\">True. Found in [this post](https://medium.com/swlh/numpy-why-is-it-so-fast-8087f4da4d79)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing bad code found [here](https://towardsdatascience.com/how-fast-numpy-really-is-e9111df44347)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499999999500000000\n",
      "Time taken: 8.36018705368042 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "count = 1000000000 # one billion\n",
    "\n",
    "normalRange = range(count)\n",
    "print(sum(normalRange))\n",
    "\n",
    "print(\"Time taken: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499999999500000000\n",
      "Time taken: 1.2841331958770752 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "count = 1000000000 # one billion\n",
    "\n",
    "numpyRange = np.arange(count)\n",
    "print(numpyRange.sum())\n",
    "\n",
    "print(\"Time taken: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">But this makes the mistake of benchmarking more than just the Target function!!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 ns ± 0.0346 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "normalRange = range(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835 ms ± 10 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "normalRange = np.arange(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Let's run the benchmark without all the clutter</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.61 s ± 821 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "sum(normalRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 ms ± 116 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "np.sum(numpyRange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">100x faster!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test contiguity\n",
    "\n",
    "\n",
    "We're gonna use A dumb program to sum elemnets by accessing them all sequentially. If one is contiguous but another is not, we should see huge difference in access times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_numpy = randint.rvs(low=0, high=9000, size=100000000) # I increased this\n",
    "a_list = list(a_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "pe7e9ETrSTF0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51 s ± 31.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "summation = 0\n",
    "\n",
    "for i in range(len(a_list)):\n",
    "    summation += a_list[i]\n",
    "\n",
    "# print(summation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "7bmRLgnnQ8jJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.93 s ± 61.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "summation = 0\n",
    "\n",
    "for i in range(len(a_numpy)):\n",
    "    summation += a_numpy[i]\n",
    "\n",
    "# print(summation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXhNYPrGXvz8"
   },
   "source": [
    "<font color=\"red\">Wow! Numpy access is 50% slower than a regular Python lists. That's especially surprising bcs. Lists are heterogeneous - you can have elements of different types and therefore sizes in them, so indexing is not as straightforward. See [this great StackOverflow post](https://stackoverflow.com/questions/35020604/why-is-numpy-list-access-slower-than-vanilla-python) for more info why this happens</font>\n",
    "\n",
    "And yet, when we try this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RfESh6-T0o7R"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "sum(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02r-jtMBXgF_"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "summation = np.sum(a_numpy)\n",
    "# print(summation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76nnMIrnZRos"
   },
   "outputs": [],
   "source": [
    "print(np.sum(a_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Z2o6bavXxjJ"
   },
   "source": [
    "<font color=\"orange\">Numpy is incredibly faster. So fast that I had to remove the print() bcs. it was noticeably affecting the runtime. But also sum(list) is 2x faster!</font>\n",
    "\n",
    "<font color=\"red\">So Numpy isn't just \"faster\" by some kind of magic. In some cases it's even slower. Generally, if your code has for loops, you're not taking advantage of Numpy. See my Part 2 for a deep dive behind Numpy</font>\n",
    "\n",
    "\n",
    "Now let us compare to [Python arrays](https://docs.python.org/3/library/array.html). To do this, we need to specify the data type we're using.\n",
    "As we can see, the numpy array is type int64. That corresponds to 'l' in python arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yk3jissBxkPQ"
   },
   "outputs": [],
   "source": [
    "np.info(a_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMmOSlHVxQmF"
   },
   "outputs": [],
   "source": [
    "from array import array\n",
    "\n",
    "a_array = array('l', a_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5p8k3OpyZhH"
   },
   "source": [
    "#### Let's see how much memory Python arrays take vs. Numpy vs. Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtXm1mx5yHrM"
   },
   "outputs": [],
   "source": [
    "print(\"Python list: Size in MB: \", sys.getsizeof(a_array) / 1024 / 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCPMt9T_ygVC"
   },
   "source": [
    "<font color=\"orange\">As we see, Python arrays take pretty much the same exact amount of space as a Numpy array</font>\n",
    "\n",
    "\n",
    "### Let's sum up the elements (sequential access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snHGCMpQyo8k"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "summation = 0\n",
    "\n",
    "for i in range(len(a_array)):\n",
    "    summation += a_array[i]\n",
    "\n",
    "print(summation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_kCCHIo1PMM"
   },
   "source": [
    "<font color=\"orange\">But arrays are supposed to have faster access! :(</font>\n",
    "\n",
    "Let's try the built-in sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0POz23e0dNY"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "sum(a_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbKZxgQk1KaB"
   },
   "source": [
    "Ahh, there's the benefit we expected of using arrays - 4.26s vs. 10s to run. About 2x as fast as summing Lists\n",
    "\n",
    "\n",
    "This is most likely due to contiguous memory access. Unfortunately, I cannot see whether the list elements are stored contiguously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eadldvz43EPh"
   },
   "outputs": [],
   "source": [
    "# Need to delete some elements bcs. Colab Free runs out of memory\n",
    "del a_array\n",
    "del a_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5BuAH__x8bU"
   },
   "source": [
    "## Let's test the hypothesis that Numpy parallelizes computation\n",
    "\n",
    "##### Let's create another such array and do some Matrix-matrix multiplication, while watching CPU core usage\n",
    "\n",
    "Check out [this cool library](https://github.com/InfuseAI/colab-xterm) to do this on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_AM93wcmCK1E"
   },
   "outputs": [],
   "source": [
    "a_numpy = randint.rvs(low=0, high=9000, size=(1000, 20000))\n",
    "b_numpy = randint.rvs(low=0, high=9000, size=(20000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkwH9H1vPHQc",
    "outputId": "82ad0c31-606c-4964-c7d1-39a8c3b41832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.67 s ± 6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 2\n",
    "\n",
    "a_numpy @ b_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.info(a_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's test [Dask](https://www.dask.org/get-started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del a_numpy\n",
    "del b_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "import dask.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dask = dask.array.from_array(randint.rvs(low=0, high=9000, size=(10000, 10000)))\n",
    "b_dask = dask.array.from_array(randint.rvs(low=0, high=9000, size=(10000, 10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "dask.array.matmul(a_dask, b_dask).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also Sum up all array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.array.sum(dask.array.matmul(a_dask, b_dask)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# This was for int64\n",
    "dask.array.matmul(a_dask, b_dask).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del a_dask\n",
    "del b_dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Trying lower precision</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = randint.rvs(low=0, high=9000, size=(10000, 100000))\n",
    "np.info(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.astype(np.int16)\n",
    "np.info(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rNpuyS4k99p"
   },
   "source": [
    "https://medium.com/swlh/numpy-why-is-it-so-fast-8087f4da4d79\n",
    "\n",
    "\n",
    "This guy says\n",
    "\n",
    "\n",
    "1. Lists cost more memory than np arrays, since metadata for each element\n",
    "\n",
    "2. No type checking needed when reading for same reason\n",
    "\n",
    "3. Contiguous\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/how-fast-numpy-really-is-e9111df44347\n",
    "\n",
    "This one doesn't elaborate on reasons why\n",
    "\n",
    "https://towardsdatascience.com/is-your-numpy-optimized-for-speed-c1d2b2ba515\n",
    "\n",
    "This guy gives the real reason but doesn't explain why. Says how to choose BLAS\n",
    "\n",
    "\n",
    "https://www.geeksforgeeks.org/why-numpy-is-faster-in-python/\n",
    "\n",
    "\n",
    "This one is plain wrong. Python doesn't use any data-level parallelism. If it did, the speedup would be limited by the number of CPU cores you have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Twice as fast when B in Fortran order</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_numpy_fortran = np.asfortranarray(b_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "a_numpy @ b_numpy_fortran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del a_numpy\n",
    "del b_numpy_fortran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QdrGJkFCYTK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
